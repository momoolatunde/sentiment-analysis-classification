{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgD_3FJwaES2"
   },
   "source": [
    "# **Sentiment Classification - Deep Learning - Stopwords Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLJhqTgS68An"
   },
   "source": [
    "# **Prerequisites**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFnczcAc7Mav"
   },
   "source": [
    "**Install Required Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KSxo3JxS7Hxd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets -q\n",
    "!pip install spacy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-0Iv3Os7QDx"
   },
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y0ne7wIg7UU7"
   },
   "outputs": [],
   "source": [
    "from imdb_data_loader import load_and_prepare_imdb_dataset\n",
    "\n",
    "trainData, testData = load_and_prepare_imdb_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTGBM1n97W6M"
   },
   "source": [
    "# **Dataset Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_8fuEvh7Zdq"
   },
   "source": [
    "**Data Checks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IxYSlnBL7dGO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vVbKoC4i7ndU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rjHEXnao7g0N"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love sci-fi and am willing to put up with a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worth the entertainment value of a rental, esp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its a totally average film with a few semi-alr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STAR RATING: ***** Saturday Night **** Friday ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First off let me say, If you haven't enjoyed a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I love sci-fi and am willing to put up with a ...      0\n",
       "1  Worth the entertainment value of a rental, esp...      0\n",
       "2  its a totally average film with a few semi-alr...      0\n",
       "3  STAR RATING: ***** Saturday Night **** Friday ...      0\n",
       "4  First off let me say, If you haven't enjoyed a...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "53ZeXaAK7lF1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojlNeIIlKJwH"
   },
   "source": [
    "**Remove Duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DXi_uGDuKKlC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataDuplicates = trainData['text'].duplicated().sum()\n",
    "\n",
    "trainDataDuplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "64jpgJelKM9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24904, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noTrainDataDuplicates = trainData.drop_duplicates(subset='text')\n",
    "\n",
    "noTrainDataDuplicatesShape = noTrainDataDuplicates.shape\n",
    "\n",
    "noTrainDataDuplicatesShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DPVb3LSWKewZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataDuplicates = testData['text'].duplicated().sum()\n",
    "\n",
    "testDataDuplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "u2C7uaJ4KfXL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24801, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noTestDataDuplicates = testData.drop_duplicates(subset='text')\n",
    "\n",
    "noTestDataDuplicatesShape = noTestDataDuplicates.shape\n",
    "\n",
    "noTestDataDuplicatesShape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wwJa1nfKlqB"
   },
   "source": [
    "# **Stopwords Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_oN-5HqOR3KV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\momo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from stopwords_preprocessing import preprocess_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oRQihYRZKoEN"
   },
   "outputs": [],
   "source": [
    "rawtrainData = noTrainDataDuplicates.copy()\n",
    "rawtestData = noTestDataDuplicates.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dtZ6gWLzKqTq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\research-dissertation\\codes\\stopwords_preprocessing.py:21: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    }
   ],
   "source": [
    "trainDataSw = rawtrainData['text'].apply(preprocess_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "b5sOD8xuKuxk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: rented curious yellow video store controversy surrounded first released also heard first seized customs ever tried enter country therefore fan films considered controversial really see plot centered around young swedish drama student named lena wants learn everything life particular wants focus attentions making sort documentary average swede thought certain political issues vietnam war race issues united states asking politicians ordinary denizens stockholm opinions politics sex drama teacher classmates married kills curious yellow years ago considered pornographic really sex nudity scenes far even shot like cheaply made porno countrymen mind find shocking reality sex nudity major staple swedish cinema even ingmar bergman arguably answer good old boy john ford sex scenes commend filmmakers fact sex shown film shown artistic purposes rather shock people make money shown pornographic theaters america curious yellow good film anyone wanting study meat potatoes pun intended swedish cinema really film much plot\n",
      "Index 1: curious yellow risible pretentious steaming pile matter one political views film hardly taken seriously level claim frontal male nudity automatic true seen r rated films male nudity granted offer fleeting views r rated films gaping vulvas flapping labia nowhere exist goes crappy cable shows schlongs swinging breeze clitoris sight pretentious indie movies like brown bunny treated site vincent gallo throbbing johnson trace pink visible chloe sevigny crying implying double standard matters nudity mentally obtuse take account one unavoidably obvious anatomical difference men women genitals display actresses appears nude said man fact generally see female genitals american film anything short porn explicit erotica alleged double standard less double standard admittedly depressing ability come terms culturally insides women bodies\n",
      "Index 2: avoid making type film future film interesting experiment tells cogent might feel virtuous sitting thru touches many important issues without discernable motive viewer comes away new perspectives unless one comes one one mind wanders invariably pointless might better spend one tears eyes staring window tree growing\n"
     ]
    }
   ],
   "source": [
    "for index, value in trainDataSw.items():\n",
    "    print(f\"Index {index}: {value}\")\n",
    "    if index == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jni2W2NjKwwB"
   },
   "outputs": [],
   "source": [
    "testDataSw = rawtestData['text'].apply(preprocess_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IfkXIyy1Kxjh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: love sci fi willing put lot sci fi movies tv usually underfunded appreciated misunderstood tried like really good tv sci fi babylon star trek original silly prosthetics cheap cardboard sets stilted dialogues cg match background painfully one dimensional characters overcome sci fi setting sure think babylon good sci fi tv clich√©d uninspiring us viewers might like emotion character development sci fi genre take seriously cf star trek may treat important issues yet serious philosophy really difficult care characters simply foolish missing spark life actions reactions wooden predictable often painful watch makers earth know rubbish always say gene roddenberry earth otherwise people would continue watching roddenberry ashes must turning orbit dull cheap poorly edited watching without advert breaks really brings home trudging trabant show lumbers space spoiler kill main character bring back another actor jeeez dallas\n",
      "Index 1: worth entertainment value rental especially like action movies one features usual car chases fights great van damme kick style shooting battles shell load shotgun even terrorist style bombs entertaining competently handled nothing really blows away seen share plot made interesting inclusion rabbit clever hardly profound many characters heavily stereotyped angry veterans terrified illegal aliens crooked cops indifferent feds bitchy tough lady station head crooked politician fat federale looks like typecast mexican hollywood movie passably acted nothing thought main villains pretty well done fairly well acted end movie certainly knew good guys emotional lift really bad ones got deserts simplistic expecting hamlet right thing found really annoying constant cuts vds daughter last fight bad good passable\n",
      "Index 2: totally average film semi alright action sequences make plot seem little better remind viewer classic van dam films parts plot make sense seem added use tears eyes end plot basic type leave viewer guessing twists obvious beginning end scene flask backs make sense added seem little relevance history van dam character really worth watching bit disappointed end production even though apparent shot low budget certain shots sections film poor directed quality\n"
     ]
    }
   ],
   "source": [
    "for index, value in testDataSw.items():\n",
    "    print(f\"Index {index}: {value}\")\n",
    "    if index == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wt4cK1IjJrY8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim_model_downloader import download_and_save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim_model_api import load_gensim_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# download_and_save_model('word2vec-google-news-300', 'word2vec_vector.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_wv = load_gensim_model('word2vec_vector.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Glove**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim_model_api import load_gensim_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_and_save_model('glove-wiki-gigaword-300', 'glove_vector.kv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_wv = load_gensim_model('glove_vector.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tokenisation and Padding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(trainDataSw)\n",
    "\n",
    "trainToken = tokenizer.texts_to_sequences(trainDataSw)\n",
    "testToken = tokenizer.texts_to_sequences(testDataSw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths = [len(x) for x in trainToken]\n",
    "percentile_90 = np.percentile(sequence_lengths, 90)\n",
    "max_length = int(percentile_90)\n",
    "\n",
    "trainPadded = pad_sequences(trainToken, maxlen=max_length, padding='post')\n",
    "testPadded = pad_sequences(testToken, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in word2vec_wv:\n",
    "        embedding_vector = word2vec_wv[word]\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_word2vec = Embedding(len(tokenizer.word_index) + 1,\n",
    "                            embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in glove_wv:\n",
    "        embedding_vector = glove_wv[word]\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_glove = Embedding(len(tokenizer.word_index) + 1,\n",
    "                            embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GlobalMaxPooling1D, Embedding, Dropout\n",
    "\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(embedding_word2vec)\n",
    "model_cnn.add(Conv1D(128, 5, activation='relu'))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(10, activation='relu'))\n",
    "model_cnn.add(Dropout(0.5))\n",
    "model_cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_cnn.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=[F1Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "623/623 [==============================] - 24s 36ms/step - loss: 0.4511 - f1_score: 0.6885 - val_loss: 0.4488 - val_f1_score: 0.9137\n",
      "Epoch 2/5\n",
      "623/623 [==============================] - 21s 34ms/step - loss: 0.3067 - f1_score: 0.8401 - val_loss: 0.4244 - val_f1_score: 0.9174\n",
      "Epoch 3/5\n",
      "623/623 [==============================] - 22s 35ms/step - loss: 0.2224 - f1_score: 0.8967 - val_loss: 0.4505 - val_f1_score: 0.9160\n",
      "Epoch 4/5\n",
      "623/623 [==============================] - 22s 35ms/step - loss: 0.1532 - f1_score: 0.9333 - val_loss: 0.5716 - val_f1_score: 0.9020\n",
      "Epoch 5/5\n",
      "623/623 [==============================] - 22s 36ms/step - loss: 0.0991 - f1_score: 0.9594 - val_loss: 0.3998 - val_f1_score: 0.9439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25878779190>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.fit(trainPadded, rawtrainData['label'], epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.save('model_cnn_word2vec.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 9s 11ms/step - loss: 0.3991 - f1_score: 0.8732\n",
      "Test F1 Score CNN - Word2Vec: 0.873186469078064\n"
     ]
    }
   ],
   "source": [
    "loss, f1_cnn_word2vec = model_cnn.evaluate(testPadded, rawtestData['label'])\n",
    "print(f\"Test F1 Score CNN - Word2Vec: {f1_cnn_word2vec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GlobalMaxPooling1D, Embedding, Dropout\n",
    "\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(embedding_glove)\n",
    "model_cnn.add(Conv1D(128, 5, activation='relu'))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(10, activation='relu'))\n",
    "model_cnn.add(Dropout(0.5))\n",
    "model_cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_cnn.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=[F1Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "623/623 [==============================] - 16s 24ms/step - loss: 0.5084 - f1_score: 0.4889 - val_loss: 0.5802 - val_f1_score: 0.8650\n",
      "Epoch 2/5\n",
      "623/623 [==============================] - 14s 23ms/step - loss: 0.3962 - f1_score: 0.7654 - val_loss: 0.9136 - val_f1_score: 0.7407\n",
      "Epoch 3/5\n",
      "623/623 [==============================] - 15s 23ms/step - loss: 0.3454 - f1_score: 0.8002 - val_loss: 0.6073 - val_f1_score: 0.8745\n",
      "Epoch 4/5\n",
      "623/623 [==============================] - 14s 23ms/step - loss: 0.3020 - f1_score: 0.8311 - val_loss: 0.4828 - val_f1_score: 0.9156\n",
      "Epoch 5/5\n",
      "623/623 [==============================] - 15s 23ms/step - loss: 0.2531 - f1_score: 0.8614 - val_loss: 0.6074 - val_f1_score: 0.8984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x256f1df2890>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.fit(trainPadded, rawtrainData['label'], epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.save('model_cnn_glove.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 6s 8ms/step - loss: 0.3923 - f1_score: 0.8553\n",
      "Test F1 Score CNN - Glove: 0.8552526831626892\n"
     ]
    }
   ],
   "source": [
    "loss, f1_cnn_glove = model_cnn.evaluate(testPadded, rawtestData['label'])\n",
    "print(f\"Test F1 Score CNN - Glove: {f1_cnn_glove}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution Neural Network - Long Short-Term Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, Conv1D, MaxPooling1D, LSTM\n",
    "\n",
    "model_cnn_lstm = Sequential()\n",
    "model_cnn_lstm.add(embedding_word2vec)\n",
    "model_cnn_lstm.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model_cnn_lstm.add(MaxPooling1D(pool_size=4))\n",
    "model_cnn_lstm.add(LSTM(128))\n",
    "model_cnn_lstm.add(Dense(10, activation='relu'))\n",
    "model_cnn_lstm.add(Dropout(0.5))\n",
    "model_cnn_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_cnn_lstm.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=[F1Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "623/623 [==============================] - 38s 61ms/step - loss: 0.2970 - f1_score: 0.8665 - val_loss: 0.3254 - val_f1_score: 0.9430\n",
      "Epoch 2/5\n",
      "623/623 [==============================] - 37s 60ms/step - loss: 0.2551 - f1_score: 0.8954 - val_loss: 0.6373 - val_f1_score: 0.8757\n",
      "Epoch 3/5\n",
      "623/623 [==============================] - 38s 60ms/step - loss: 0.2066 - f1_score: 0.9217 - val_loss: 0.2824 - val_f1_score: 0.9529\n",
      "Epoch 4/5\n",
      "623/623 [==============================] - 38s 61ms/step - loss: 0.1602 - f1_score: 0.9415 - val_loss: 0.6961 - val_f1_score: 0.8919\n",
      "Epoch 5/5\n",
      "623/623 [==============================] - 37s 60ms/step - loss: 0.1292 - f1_score: 0.9552 - val_loss: 1.0011 - val_f1_score: 0.8604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x256f1fe1b10>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_lstm.fit(trainPadded, rawtrainData['label'], epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_lstm.save('model_cnn_lstm_word2vec.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 16s 21ms/step - loss: 0.5622 - f1_score: 0.8343\n",
      "Test F1 Score - Word2Vec: 0.8343249559402466\n"
     ]
    }
   ],
   "source": [
    "loss, f1_cnn_lstm_word2vec = model_cnn_lstm.evaluate(testPadded, rawtestData['label'])\n",
    "print(f\"Test F1 Score - Word2Vec: {f1_cnn_lstm_word2vec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, Conv1D, MaxPooling1D, LSTM\n",
    "\n",
    "model_cnn_lstm = Sequential()\n",
    "model_cnn_lstm.add(embedding_glove)\n",
    "\n",
    "# Convolutional Layer\n",
    "model_cnn_lstm.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model_cnn_lstm.add(MaxPooling1D(pool_size=4))\n",
    "\n",
    "# LSTM Layer\n",
    "model_cnn_lstm.add(LSTM(128))\n",
    "\n",
    "# Fully Connected Layers\n",
    "model_cnn_lstm.add(Dense(10, activation='relu'))\n",
    "\n",
    "model_cnn_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_cnn_lstm.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=[F1Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "623/623 [==============================] - 45s 65ms/step - loss: 0.5785 - f1_score: 0.4843 - val_loss: 0.4862 - val_f1_score: 0.9378\n",
      "Epoch 2/5\n",
      "623/623 [==============================] - 38s 61ms/step - loss: 0.3590 - f1_score: 0.7867 - val_loss: 0.3655 - val_f1_score: 0.9180\n",
      "Epoch 3/5\n",
      "623/623 [==============================] - 38s 60ms/step - loss: 0.2787 - f1_score: 0.8498 - val_loss: 0.3697 - val_f1_score: 0.9235\n",
      "Epoch 4/5\n",
      "623/623 [==============================] - 34s 55ms/step - loss: 0.2112 - f1_score: 0.8942 - val_loss: 0.5020 - val_f1_score: 0.8897\n",
      "Epoch 5/5\n",
      "623/623 [==============================] - 39s 62ms/step - loss: 0.1561 - f1_score: 0.9263 - val_loss: 0.6155 - val_f1_score: 0.8828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25873d8c050>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_lstm.fit(trainPadded, rawtrainData['label'], epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_lstm.save('model_cnn_lstm_glove.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 16s 20ms/step - loss: 0.4055 - f1_score: 0.8496\n",
      "Test F1 Score - Glove: 0.8495842814445496\n"
     ]
    }
   ],
   "source": [
    "loss, f1_cnn_lstm_glove = model_cnn_lstm.evaluate(testPadded, rawtestData['label'])\n",
    "print(f\"Test F1 Score - Glove: {f1_cnn_lstm_glove}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bidirectional Long Short-Term Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "model_bilstm = Sequential()\n",
    "model_bilstm.add(embedding_word2vec)\n",
    "model_bilstm.add(Bidirectional(LSTM(128)))\n",
    "model_bilstm.add(Dense(10, activation='relu'))\n",
    "model_bilstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_bilstm.compile(optimizer='adam', \n",
    "                     loss='binary_crossentropy', \n",
    "                     metrics=[F1Score()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "623/623 [==============================] - 182s 282ms/step - loss: 0.6125 - accuracy: 0.6729 - f1_score: 0.4061 - val_loss: 0.4808 - val_accuracy: 0.8458 - val_f1_score: 0.9165\n",
      "Epoch 2/5\n",
      "623/623 [==============================] - 176s 282ms/step - loss: 0.3986 - accuracy: 0.8257 - f1_score: 0.7616 - val_loss: 0.5320 - val_accuracy: 0.7747 - val_f1_score: 0.8731\n",
      "Epoch 3/5\n",
      "623/623 [==============================] - 175s 281ms/step - loss: 0.2999 - accuracy: 0.8747 - f1_score: 0.8324 - val_loss: 0.2562 - val_accuracy: 0.9097 - val_f1_score: 0.9527\n",
      "Epoch 4/5\n",
      "623/623 [==============================] - 142s 228ms/step - loss: 0.2742 - accuracy: 0.8884 - f1_score: 0.8504 - val_loss: 0.6993 - val_accuracy: 0.7137 - val_f1_score: 0.8329\n",
      "Epoch 5/5\n",
      "623/623 [==============================] - 172s 276ms/step - loss: 0.2529 - accuracy: 0.8989 - f1_score: 0.8648 - val_loss: 0.3718 - val_accuracy: 0.8552 - val_f1_score: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2582d09b3d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bilstm.fit(trainPadded, rawtrainData['label'], epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bilstm.save('model_bilstm_word2vec.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 73s 94ms/step - loss: 0.2909 - accuracy: 0.8793 - f1_score: 0.8778\n",
      "Test F1 Score - BiLSTM Word2Vec: 0.8778058290481567\n"
     ]
    }
   ],
   "source": [
    "loss, _, f1_bilstm_word2vec = model_bilstm.evaluate(testPadded, rawtestData['label'])\n",
    "print(f\"Test F1 Score - BiLSTM Word2Vec: {f1_bilstm_word2vec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "model_bilstm = Sequential()\n",
    "model_bilstm.add(embedding_word2vec)\n",
    "model_bilstm.add(Bidirectional(LSTM(128)))\n",
    "model_bilstm.add(Dense(10, activation='relu'))\n",
    "model_bilstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_bilstm.compile(optimizer='adam', \n",
    "                     loss='binary_crossentropy', \n",
    "                     metrics=[F1Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "623/623 [==============================] - 110s 172ms/step - loss: 0.5772 - f1_score: 0.5133 - val_loss: 1.0610 - val_f1_score: 0.0024\n",
      "Epoch 2/5\n",
      "623/623 [==============================] - 108s 173ms/step - loss: 0.4212 - f1_score: 0.7286 - val_loss: 0.3169 - val_f1_score: 0.9409\n",
      "Epoch 3/5\n",
      "623/623 [==============================] - 109s 174ms/step - loss: 0.2996 - f1_score: 0.8343 - val_loss: 0.4581 - val_f1_score: 0.8969\n",
      "Epoch 4/5\n",
      "623/623 [==============================] - 110s 177ms/step - loss: 0.2764 - f1_score: 0.8498 - val_loss: 0.6269 - val_f1_score: 0.8585\n",
      "Epoch 5/5\n",
      "623/623 [==============================] - 111s 178ms/step - loss: 0.2525 - f1_score: 0.8605 - val_loss: 0.3572 - val_f1_score: 0.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25875e9a190>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bilstm.fit(trainPadded, rawtrainData['label'], epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bilstm.save('model_bilstm_glove.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 50s 64ms/step - loss: 0.2950 - f1_score: 0.8777\n",
      "Test F1 Score - BiLSTM Glove: 0.8777210116386414\n"
     ]
    }
   ],
   "source": [
    "loss, f1_bilstm_glove = model_bilstm.evaluate(testPadded, rawtestData['label'])\n",
    "print(f\"Test F1 Score - BiLSTM Glove: {f1_bilstm_glove}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_results import generate_dl_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.873186469078064,\n",
       " 0.8552526831626892,\n",
       " 0.8778058290481567,\n",
       " 0.8777210116386414,\n",
       " 0.8343249559402466,\n",
       " 0.8495842814445496)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_cnn_word2vec, f1_cnn_glove, f1_bilstm_word2vec, f1_bilstm_glove, f1_cnn_lstm_word2vec, f1_cnn_lstm_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYpkjiSAVj0M"
   },
   "outputs": [],
   "source": [
    "resultsDF = generate_dl_results_df(f1_cnn_word2vec, f1_cnn_glove, f1_bilstm_word2vec, f1_bilstm_glove, f1_cnn_lstm_word2vec, f1_cnn_lstm_glove)\n",
    "print(resultsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYpkjiSAVj0M"
   },
   "outputs": [],
   "source": [
    "resultsDF.to_csv(\"final_dl_models_stopwords_prep.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuvptv9SVjrL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOL03ukDTATxLkpbBq0g8Ag",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1ZVDd_9O8eddBkUyyM9Vhr5rHvhTnLBol",
   "provenance": [
    {
     "file_id": "1ZVDd_9O8eddBkUyyM9Vhr5rHvhTnLBol",
     "timestamp": 1705376268080
    },
    {
     "file_id": "1hujpqpuuR_ekIzBjWsOOvxY0kmOzW50F",
     "timestamp": 1705255316719
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
