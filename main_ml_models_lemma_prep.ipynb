{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgD_3FJwaES2"
   },
   "source": [
    "# **Sentiment Classification - Machine Learning / Lemmatisation Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLJhqTgS68An"
   },
   "source": [
    "# **Prerequisites**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFnczcAc7Mav"
   },
   "source": [
    "**Install Required Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KSxo3JxS7Hxd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# nstall the 'datasets' library \n",
    "!pip install datasets -q\n",
    "\n",
    "# install the 'spacy' library\n",
    "!pip install spacy -q\n",
    "\n",
    "# installing the joblib library\n",
    "!pip install joblib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KSxo3JxS7Hxd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# downloads the small English model (en_core_web_sm) for the Spacy library\n",
    "!python -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-0Iv3Os7QDx"
   },
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y0ne7wIg7UU7"
   },
   "outputs": [],
   "source": [
    "# import the 'load_and_prepare_imdb_dataset' function from the 'imdb_data_loader'\n",
    "from imdb_data_loader import load_and_prepare_imdb_dataset\n",
    "\n",
    "# call the 'load_and_prepare_imdb_dataset' function to import the IMDB dataset\n",
    "trainData, testData = load_and_prepare_imdb_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTGBM1n97W6M"
   },
   "source": [
    "# **Dataset Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_8fuEvh7Zdq"
   },
   "source": [
    "**Data Checks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IxYSlnBL7dGO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the 'head()' method on the 'trainData' DataFrame to inspect the first five rows\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vVbKoC4i7ndU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the shape of the 'trainData' DataFrame\n",
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rjHEXnao7g0N"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love sci-fi and am willing to put up with a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worth the entertainment value of a rental, esp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its a totally average film with a few semi-alr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STAR RATING: ***** Saturday Night **** Friday ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First off let me say, If you haven't enjoyed a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I love sci-fi and am willing to put up with a ...      0\n",
       "1  Worth the entertainment value of a rental, esp...      0\n",
       "2  its a totally average film with a few semi-alr...      0\n",
       "3  STAR RATING: ***** Saturday Night **** Friday ...      0\n",
       "4  First off let me say, If you haven't enjoyed a...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the 'head()' method on the 'testData' DataFrame to inspect the first five rows\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "53ZeXaAK7lF1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the shape of the 'testData' DataFrame\n",
    "testData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojlNeIIlKJwH"
   },
   "source": [
    "**Remove Duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DXi_uGDuKKlC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the number of duplicated entries in the 'text' column of the 'trainData' DataFrame\n",
    "trainDataDuplicates = trainData['text'].duplicated().sum()\n",
    "trainDataDuplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "64jpgJelKM9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24904, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicate rows from 'trainData' based on the 'text' column\n",
    "noTrainDataDuplicates = trainData.drop_duplicates(subset='text')\n",
    "noTrainDataDuplicatesShape = noTrainDataDuplicates.shape\n",
    "\n",
    "# get the shape of the 'noTrainDataDuplicates' DataFrame\n",
    "noTrainDataDuplicatesShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DPVb3LSWKewZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the number of duplicated entries in the 'text' column of the 'testData' DataFrame\n",
    "testDataDuplicates = testData['text'].duplicated().sum()\n",
    "testDataDuplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "u2C7uaJ4KfXL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24801, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicate rows from 'testData' based on the 'text' column\n",
    "noTestDataDuplicates = testData.drop_duplicates(subset='text')\n",
    "noTestDataDuplicatesShape = noTestDataDuplicates.shape\n",
    "\n",
    "noTestDataDuplicatesShape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wwJa1nfKlqB"
   },
   "source": [
    "# **Lemmatisation Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_oN-5HqOR3KV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the preprocessing function 'preprocess_lemma' from 'lemma_preprocessing'\n",
    "\n",
    "# Convert text to lowercase.\n",
    "# Remove HTML tags using BeautifulSoup.\n",
    "# Handle contractions.\n",
    "# Expand acronyms.\n",
    "# Tokenize the text using SpaCy.\n",
    "# Remove punctuation tokens.\n",
    "# Remove non-alphabetic characters.\n",
    "# Added lemmatisation\n",
    "\n",
    "from lemma_preprocessing import preprocess_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oRQihYRZKoEN"
   },
   "outputs": [],
   "source": [
    "# create copies of the noTrainDataDuplicates and noTestDataDuplicates DataFrames\n",
    "rawtrainData = noTrainDataDuplicates.copy()\n",
    "rawtestData = noTestDataDuplicates.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\research-dissertation\\codes\\lemma_preprocessing.py:15: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    }
   ],
   "source": [
    "# apply the 'preprocess_lemma' function to each text entry in the 'rawtrainData' DataFrame\n",
    "trainDataLemma = rawtrainData['text'].apply(preprocess_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "b5sOD8xuKuxk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: I rent I be curious yellow from my video store because of all the controversy that surround it when it be first release in 1967 I also hear that at first it be seize by you.s customs if it ever try to enter this country therefore be a fan of film consider controversial I really have to see this for myself.the plot be center around a young swedish drama student name lena who want to learn everything she can about life in particular she want to focus her attention to make some sort of documentary on what the average swede think about certain political issue such as the vietnam war and race issue in the united states in between ask politician and ordinary denizen of stockholm about their opinion on politic she have sex with her drama teacher classmate and marry men.what kill I about I be curious yellow be that 40 year ago this be consider pornographic really the sex and nudity scene be few and far between even then it have it be not shoot like some cheaply make porno while my countryman mind find it shocking in reality sex and nudity be a major staple in swedish cinema even ingmar bergman arguably their answer to good old boy john ford have sex scene in his films.i do commend the filmmaker for the fact that any sex show in the film be show for artistic purpose rather than just to shock people and make money to be show in pornographic theater in america I be curious yellow be a good film for anyone want to study the meat and potato no pun intend of swedish cinema but really this film do not have much of a plot\n",
      "Index 1: I be curious yellow be a risible and pretentious steaming pile it do not matter what one 's political view be because this film can hardly be take seriously on any level as for the claim that frontal male nudity be an automatic nc-17 that be not true I have see r rate film with male nudity grant they only offer some fleeting view but where be the r rate film with gape vulvas and flap labia nowhere because they do not exist the same go for those crappy cable show schlong swinge in the breeze but not a clitoris in sight and those pretentious indie movie like the brown bunny in which we be treat to the site of vincent gallo 's throbbing johnson but not a trace of pink visible on chloe sevigny before cry or imply double standard in matter of nudity the mentally obtuse should take into account one unavoidably obvious anatomical difference between man and woman there be no genital on display when actress appear nude and the same can not be say for a man in fact you generally will not see female genital in an american film in anything short of porn or explicit erotica this allege double standard be less a double standard than an admittedly depressing ability to come to term culturally with the inside of woman 's body\n",
      "Index 2: if only to avoid make this type of film in the future this film be interesting as an experiment but tell no cogent story.one might feel virtuous for sit thru it because it touch on so many important issue but it do so without any discernable motive the viewer come away with no new perspective unless one come up with one while one 's mind wander as it will invariably do during this pointless film).one might well spend one 's tear in my eye stare out a window at a tree grow\n"
     ]
    }
   ],
   "source": [
    "# print the first three preprocessed text entries (train data) to verify the preprocessing step\n",
    "for index, value in trainDataLemma.items():\n",
    "    print(f\"Index {index}: {value}\")\n",
    "    if index == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the 'preprocess_lemma' function to each text entry in the 'rawtestData' DataFrame\n",
    "testDataLemma = rawtestData['text'].apply(preprocess_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IfkXIyy1Kxjh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: I love sci fi and be willing to put up with a lot sci fi movie tv be usually underfunded under appreciated and misunderstood I try to like this I really do but it be to good tv sci fi as babylon 5 be to star trek the original silly prosthetic cheap cardboard set stilte dialogue cg that do not match the background and painfully one dimensional character can not be overcome with a sci fi setting I be sure there be those of you out there who think babylon 5 be good sci fi tv it have it be not it have it be clich√©d and uninspire while we viewer might like emotion and character development sci fi be a genre that do not take itself seriously cf star trek it may treat important issue yet not as a serious philosophy it have it be really difficult to care about the character here as they be not simply foolish just miss a spark of life their action and reaction be wooden and predictable often painful to watch the maker of earth know it have it be rubbish as they have to always say gene roddenberry 's earth otherwise people would not continue watch roddenberry 's ashe must be turn in their orbit as this dull cheap poorly edit watch it without advert break really bring this home trudge trabant of a show lumber into space spoiler so kill off a main character and then bring he back as another actor jeeez dallas all over again\n",
      "Index 1: worth the entertainment value of a rental especially if you like action movie this one feature the usual car chase fight with the great van damme kick style shoot battle with the 40 shell load shotgun and even terrorist style bomb all of this be entertaining and competently handle but there be nothing that really blow you away if you have see your share before.the plot be make interesting by the inclusion of a rabbit which be clever but hardly profound many of the character be heavily stereotype the angry veteran the terrified illegal alien the crooked cop the indifferent fed the bitchy tough lady station head the crooked politician the fat federale who look like he be typecast as the mexican in a hollywood movie from the 1940 all passably act but again nothing special.i think the main villain be pretty well do and fairly well act by the end of the movie you certainly know who the good guy be and be not there be an emotional lift as the really bad one get their just desert very simplistic but then you be not expect hamlet right the only thing I find really annoying be the constant cut to vds daughter during the last fight scene.not bad not good passable 4\n",
      "Index 2: its a totally average film with a few semi alright action sequence that make the plot seem a little well and remind the viewer of the classic van dam film part of the plot do not make sense and seem to be add in to use up tear in my eye the end plot be that of a very basic type that do not leave the viewer guessing and any twist be obvious from the beginning the end scene with the flask back do not make sense as they be add in and seem to have little relevance to the history of van dam 's character not really worth watch again bit disappoint in the end production even though it be apparent it be shoot on a low budget certain shot and section in the film be of poor directed quality\n"
     ]
    }
   ],
   "source": [
    "# print the first three preprocessed text entries (test data) to verify the preprocessing step\n",
    "for index, value in testDataLemma.items():\n",
    "    print(f\"Index {index}: {value}\")\n",
    "    if index == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBP2makMK3A5"
   },
   "source": [
    "# **Feature Extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inqi3Q4RK9r_"
   },
   "source": [
    "**Bag of Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FOudkfpLK_tQ"
   },
   "outputs": [],
   "source": [
    "# import the function for creating a Bag-of-Words (BOW) representation from 'bow_text_vectorization'\n",
    "from bow_text_vectorization import create_bow_representation\n",
    "\n",
    "trainBow, testBow = create_bow_representation(trainDataLemma, testDataLemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WB0NIdE5LINa"
   },
   "source": [
    "**Term Fequency-Inverse Document Frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4ul1q5WBLI8d"
   },
   "outputs": [],
   "source": [
    "# import the function for creating a TF-IDF representation from 'tfidf_text_vectorization\n",
    "from tfidf_text_vectorization import create_tfidf_representation\n",
    "\n",
    "trainTfidf, testTfidf = create_tfidf_representation(trainDataLemma, testDataLemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8PPlMwzLO6x"
   },
   "source": [
    "# **Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-kgspf76LVd-"
   },
   "outputs": [],
   "source": [
    "# import functions for training different classifiers\n",
    "from final_machine_learning_models_evaluation import train_nb_classifier, train_svm_classifier, train_lr_classifier, evaluate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-dWk84sLRJK"
   },
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "y4DI3rQxLTcq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Naive Bayes(BOW): 0.7944898837709858\n"
     ]
    }
   ],
   "source": [
    "# train a Naive Bayes classifier using the BOW representation of the training data\n",
    "nb_model = train_nb_classifier(trainBow, rawtrainData['label'])\n",
    "f1_nb_bow = evaluate_model(nb_model, testBow, rawtestData['label'])\n",
    "\n",
    "print(f\"F1 Score for Naive Bayes(BOW): {f1_nb_bow}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "G0PtflgwLoNb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Naive Bayes(TFIDF): 0.8120191485724055\n"
     ]
    }
   ],
   "source": [
    "# train a Naive Bayes classifier using the TF-IDF representation of the training data\n",
    "nb_model = train_nb_classifier(trainTfidf, rawtrainData['label'])\n",
    "f1_nb_tfidf = evaluate_model(nb_model, testTfidf, rawtestData['label'])\n",
    "\n",
    "print(f\"F1 Score for Naive Bayes(TFIDF): {f1_nb_tfidf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPGFaXbMLte7"
   },
   "source": [
    "**Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5mZ8FptuLwCI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for SVM(BOW): 0.8347457627118643\n"
     ]
    }
   ],
   "source": [
    "# train an SVM classifier using the BOW representation of the training data\n",
    "svm_model = train_svm_classifier(trainBow, rawtrainData['label'])\n",
    "f1_svm_bow = evaluate_model(svm_model, testBow, rawtestData['label'])\n",
    "\n",
    "print(f\"F1 Score for SVM(BOW): {f1_svm_bow}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "W7O2nEvYL3m1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for SVM(TFIDF): 0.8790986098163985\n"
     ]
    }
   ],
   "source": [
    "# train an SVM classifier using the TF-IDF representation of the training data\n",
    "svm_model = train_svm_classifier(trainTfidf, rawtrainData['label'])\n",
    "f1_svm_tfidf = evaluate_model(svm_model, testTfidf, rawtestData['label'])\n",
    "\n",
    "print(f\"F1 Score for SVM(TFIDF): {f1_svm_tfidf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGKjGqnqL7F9"
   },
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RSfaHUouL_C5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Logistic Regression(BOW): 0.8638938339537143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\momo\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# train a Logistic Regression classifier using the BOW representation of the training data\n",
    "lr_model = train_lr_classifier(trainBow, rawtrainData['label'])\n",
    "f1_lr_bow = evaluate_model(lr_model, testBow, rawtestData['label'])\n",
    "\n",
    "print(f\"F1 Score for Logistic Regression(BOW): {f1_lr_bow}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wGhlr3gYMLQS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Logistic Regression(TFIDF): 0.8819486313758591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\momo\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# train a Logistic Regression classifier using the TF-IDF representation of the training data\n",
    "lr_model = train_lr_classifier(trainTfidf, rawtrainData['label'])\n",
    "f1_lr_tfidf = evaluate_model(lr_model, testTfidf, rawtestData['label'])\n",
    "\n",
    "print(f\"F1 Score for Logistic Regression(TFIDF): {f1_lr_tfidf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4OTKXp4N5Yo"
   },
   "source": [
    "# **Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "tYbjqFbTOHPS"
   },
   "outputs": [],
   "source": [
    "# import the function 'generate_results_df' from the 'model_results' module\n",
    "from model_results import generate_ml_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hMZZWrVnQb4P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  F1 Score\n",
      "0    Naive Bayes (BOW)  0.794490\n",
      "1  Naive Bayes (TFIDF)  0.812019\n",
      "2            SVM (BOW)  0.834746\n",
      "3          SVM (TFIDF)  0.879099\n",
      "4             LR (BOW)  0.863894\n",
      "5           LR (TFIDF)  0.881949\n"
     ]
    }
   ],
   "source": [
    "# generate a DataFrame 'resultsDF' using the F1 scores from different models\n",
    "resultsDF = generate_ml_results_df(f1_nb_bow, f1_nb_tfidf, f1_svm_bow, f1_svm_tfidf, f1_lr_bow, f1_lr_tfidf)\n",
    "print(resultsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "WQ1uSAltQiDQ"
   },
   "outputs": [],
   "source": [
    "# save the 'resultsDF' DataFrame to a CSV file named \"final_ml_models_basic_prep.csv\".\n",
    "resultsDF.to_csv(\"final_ml_models_lemma_prep.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNWhnLNVe0/jLNiiknbGQX4",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1hujpqpuuR_ekIzBjWsOOvxY0kmOzW50F",
     "timestamp": 1705226691334
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
